#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•Bç«™Cookieè®¤è¯
"""

import asyncio
import sys
import os
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.core.crawler import BilibiliCrawler

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)

async def test_authentication():
    """æµ‹è¯•è®¤è¯çŠ¶æ€"""
    crawler = BilibiliCrawler()
    
    try:
        await crawler.init_session()
        
        # æµ‹è¯•1: æ£€æŸ¥ç™»å½•çŠ¶æ€ - è·å–ä¸ªäººç©ºé—´ä¿¡æ¯
        logger.info("=== æµ‹è¯•1: æ£€æŸ¥ç™»å½•çŠ¶æ€ ===")
        url = "https://api.bilibili.com/x/space/myinfo"
        result = await crawler._make_request(url)
        
        if result and result.get('code') == 0:
            data = result.get('data', {})
            logger.info(f"âœ… ç™»å½•æˆåŠŸï¼ç”¨æˆ·: {data.get('name', 'Unknown')}")
            logger.info(f"   ç”¨æˆ·ID: {data.get('mid', 'Unknown')}")
            logger.info(f"   ç²‰ä¸æ•°: {data.get('follower', 'Unknown')}")
            logger.info(f"   å…³æ³¨æ•°: {data.get('following', 'Unknown')}")
        else:
            logger.error(f"âŒ ç™»å½•å¤±è´¥ï¼å“åº”: {result}")
            return False
        
        # æµ‹è¯•2: è·å–å…³æ³¨åˆ—è¡¨ï¼ˆéœ€è¦ç™»å½•ï¼‰
        logger.info("\n=== æµ‹è¯•2: è·å–å…³æ³¨åˆ—è¡¨ ===")
        url = "https://api.bilibili.com/x/relation/followings"
        params = {'vmid': data.get('mid'), 'ps': 5}
        result = await crawler._make_request(url, params)
        
        if result and result.get('code') == 0:
            followings = result.get('data', {}).get('list', [])
            logger.info(f"âœ… æˆåŠŸè·å–å…³æ³¨åˆ—è¡¨ï¼Œå…± {len(followings)} äºº")
            for following in followings[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                logger.info(f"   - {following.get('uname', 'Unknown')}")
        else:
            logger.warning(f"âš ï¸  è·å–å…³æ³¨åˆ—è¡¨å¤±è´¥: {result}")
        
        # æµ‹è¯•3: è·å–å†å²è®°å½•ï¼ˆéœ€è¦ç™»å½•ï¼‰
        logger.info("\n=== æµ‹è¯•3: è·å–è§‚çœ‹å†å² ===")
        url = "https://api.bilibili.com/x/web-interface/history/cursor"
        params = {'ps': 5}
        result = await crawler._make_request(url, params)
        
        if result and result.get('code') == 0:
            history = result.get('data', {}).get('list', [])
            logger.info(f"âœ… æˆåŠŸè·å–è§‚çœ‹å†å²ï¼Œå…± {len(history)} æ¡")
            for item in history[:3]:  # æ˜¾ç¤ºå‰3æ¡
                logger.info(f"   - {item.get('title', 'Unknown')}")
        else:
            logger.warning(f"âš ï¸  è·å–è§‚çœ‹å†å²å¤±è´¥: {result}")
        
        # æµ‹è¯•4: æµ‹è¯•éœ€è¦é«˜æƒé™çš„æ¥å£
        logger.info("\n=== æµ‹è¯•4: æµ‹è¯•æ”¶è—å¤¹åˆ—è¡¨ ===")
        url = "https://api.bilibili.com/x/v3/fav/folder/created/list-all"
        params = {'up_mid': data.get('mid')}
        result = await crawler._make_request(url, params)
        
        if result and result.get('code') == 0:
            folders = result.get('data', {}).get('list', [])
            logger.info(f"âœ… æˆåŠŸè·å–æ”¶è—å¤¹åˆ—è¡¨ï¼Œå…± {len(folders)} ä¸ª")
            for folder in folders[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                logger.info(f"   - {folder.get('title', 'Unknown')} ({folder.get('media_count', 0)}ä¸ªè§†é¢‘)")
        else:
            logger.warning(f"âš ï¸  è·å–æ”¶è—å¤¹åˆ—è¡¨å¤±è´¥: {result}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False
    finally:
        await crawler.close_session()

async def test_public_api():
    """æµ‹è¯•ä¸éœ€è¦ç™»å½•çš„å…¬å¼€API"""
    crawler = BilibiliCrawler()
    
    try:
        await crawler.init_session()
        
        logger.info("\n=== æµ‹è¯•å…¬å¼€API: è·å–çƒ­é—¨è§†é¢‘ ===")
        videos = await crawler.get_trending_videos(limit=5)
        
        if videos:
            logger.info(f"âœ… æˆåŠŸè·å– {len(videos)} ä¸ªçƒ­é—¨è§†é¢‘:")
            for i, video in enumerate(videos[:3], 1):
                logger.info(f"   {i}. {video.get('title', 'Unknown')}")
                logger.info(f"      ä½œè€…: {video.get('owner', 'Unknown')}")
                logger.info(f"      BVID: {video.get('bvid', 'Unknown')}")
        else:
            logger.error("âŒ è·å–çƒ­é—¨è§†é¢‘å¤±è´¥")
            return False
            
        return True
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å…¬å¼€APIæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False
    finally:
        await crawler.close_session()

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æµ‹è¯•Bç«™Cookieè®¤è¯...")
    
    # æµ‹è¯•å…¬å¼€API
    public_success = await test_public_api()
    
    # æµ‹è¯•è®¤è¯API
    auth_success = await test_authentication()
    
    logger.info("\n" + "="*50)
    logger.info("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    logger.info(f"   å…¬å¼€API: {'âœ… æ­£å¸¸' if public_success else 'âŒ å¤±è´¥'}")
    logger.info(f"   è®¤è¯API: {'âœ… æ­£å¸¸' if auth_success else 'âŒ å¤±è´¥'}")
    
    if auth_success:
        logger.info("ğŸ‰ Cookieè®¤è¯é…ç½®æˆåŠŸï¼å¯ä»¥ä½¿ç”¨éœ€è¦ç™»å½•çš„åŠŸèƒ½äº†ã€‚")
    else:
        logger.error("ğŸ˜ Cookieè®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥SESSDATAæ˜¯å¦æœ‰æ•ˆã€‚")
    
    return auth_success

if __name__ == "__main__":
    asyncio.run(main()) 