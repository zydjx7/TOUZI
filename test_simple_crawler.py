#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•çš„Bç«™UPä¸»æµ‹è¯•
"""

import asyncio
import sys
import os
import logging
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.core.crawler import BilibiliCrawler

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)

async def test_alternative_approach(uid: str, up_name: str):
    """ä½¿ç”¨æ›¿ä»£æ–¹æ³•æµ‹è¯•UPä¸»ä¿¡æ¯è·å–"""
    crawler = BilibiliCrawler()
    
    try:
        await crawler.init_session()
        logger.info(f"ğŸ¯ å¼€å§‹æµ‹è¯•UPä¸»: {up_name} (UID: {uid})")
        
        # æ–¹æ³•1: å°è¯•è·å–UPä¸»åŸºæœ¬ä¿¡æ¯
        logger.info("ğŸ“‹ å°è¯•è·å–UPä¸»åŸºæœ¬ä¿¡æ¯...")
        url = "https://api.bilibili.com/x/space/acc/info"
        params = {'mid': uid}
        
        # ç­‰å¾…è¶³å¤Ÿçš„æ—¶é—´
        await asyncio.sleep(10)
        result = await crawler._make_request(url, params)
        
        if result and result.get('code') == 0:
            data = result.get('data', {})
            logger.info("âœ… æˆåŠŸè·å–UPä¸»ä¿¡æ¯:")
            logger.info(f"   ç”¨æˆ·å: {data.get('name', 'Unknown')}")
            logger.info(f"   ç²‰ä¸æ•°: {data.get('follower', 0):,}")
            logger.info(f"   å…³æ³¨æ•°: {data.get('following', 0):,}")
            logger.info(f"   ç­¾å: {data.get('sign', 'Unknown')}")
            
            # æ–¹æ³•2: å°è¯•ä½¿ç”¨æœç´¢APIæ¥è·å–è§†é¢‘
            logger.info("\nğŸ” å°è¯•æœç´¢è¯¥UPä¸»çš„è§†é¢‘...")
            await asyncio.sleep(10)  # ç­‰å¾…æ›´é•¿æ—¶é—´
            
            search_query = data.get('name', up_name)
            videos = await crawler.search_videos(search_query, page_size=10)
            
            if videos:
                logger.info(f"âœ… é€šè¿‡æœç´¢æ‰¾åˆ° {len(videos)} ä¸ªç›¸å…³è§†é¢‘:")
                for i, video in enumerate(videos[:3], 1):
                    title = video.get('title', 'Unknown')
                    author = video.get('author', 'Unknown')
                    bvid = video.get('bvid', 'Unknown')
                    logger.info(f"   {i}. {title}")
                    logger.info(f"      ä½œè€…: {author} | BVID: {bvid}")
            else:
                logger.warning("âš ï¸  æœªæ‰¾åˆ°ç›¸å…³è§†é¢‘")
            
            # æ–¹æ³•3: å°è¯•è·å–ç”¨æˆ·åŠ¨æ€
            logger.info("\nğŸ“± å°è¯•è·å–ç”¨æˆ·åŠ¨æ€...")
            await asyncio.sleep(10)
            
            dynamics = await crawler.get_user_dynamics(uid)
            
            if dynamics:
                logger.info(f"âœ… æˆåŠŸè·å– {len(dynamics)} æ¡åŠ¨æ€:")
                for i, dynamic in enumerate(dynamics[:3], 1):
                    content = dynamic.get('content', '')[:50]
                    timestamp = dynamic.get('timestamp', 0)
                    try:
                        time_str = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M')
                    except:
                        time_str = "æœªçŸ¥æ—¶é—´"
                    logger.info(f"   {i}. {content}... ({time_str})")
            else:
                logger.warning("âš ï¸  æœªèƒ½è·å–åˆ°ç”¨æˆ·åŠ¨æ€")
                
            return True
            
        else:
            logger.error(f"âŒ è·å–UPä¸»ä¿¡æ¯å¤±è´¥: {result}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False
    finally:
        await crawler.close_session()

async def test_public_data_only():
    """åªæµ‹è¯•å…¬å¼€æ•°æ®ï¼Œä¸æ¶‰åŠå…·ä½“UPä¸»"""
    crawler = BilibiliCrawler()
    
    try:
        await crawler.init_session()
        
        logger.info("ğŸŒŸ æµ‹è¯•è·å–çƒ­é—¨è§†é¢‘...")
        videos = await crawler.get_trending_videos(limit=5)
        
        if videos:
            logger.info(f"âœ… æˆåŠŸè·å– {len(videos)} ä¸ªçƒ­é—¨è§†é¢‘")
            
            # æµ‹è¯•è·å–å…¶ä¸­ä¸€ä¸ªè§†é¢‘çš„è¯¦ç»†ä¿¡æ¯
            first_video = videos[0]
            bvid = first_video.get('bvid', '')
            
            if bvid:
                logger.info(f"\nğŸ” æµ‹è¯•è·å–è§†é¢‘è¯¦æƒ…: {first_video.get('title', 'Unknown')}")
                await asyncio.sleep(8)  # ç¨ç­‰
                
                video_info = await crawler.get_video_info(bvid)
                
                if video_info:
                    logger.info("âœ… æˆåŠŸè·å–è§†é¢‘è¯¦æƒ…:")
                    logger.info(f"   UPä¸»: {video_info.get('owner', {}).get('name', 'Unknown')}")
                    logger.info(f"   UPä¸»UID: {video_info.get('owner', {}).get('mid', 'Unknown')}")
                    logger.info(f"   æ’­æ”¾é‡: {video_info.get('stat', {}).get('view', 0):,}")
                    logger.info(f"   ç‚¹èµæ•°: {video_info.get('stat', {}).get('like', 0):,}")
                    
                    return video_info.get('owner', {}).get('mid', None)
        
        return None
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å…¬å¼€æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None
    finally:
        await crawler.close_session()

async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹ç®€å•æµ‹è¯•...")
    
    # å…ˆæµ‹è¯•å…¬å¼€æ•°æ®
    logger.info("="*60)
    logger.info("ç¬¬ä¸€æ­¥: æµ‹è¯•å…¬å¼€æ•°æ®è·å–")
    sample_uid = await test_public_data_only()
    
    # ç­‰å¾…æ›´é•¿æ—¶é—´å†è¿›è¡Œä¸‹ä¸€æ­¥æµ‹è¯•
    logger.info("\nâ³ ç­‰å¾…60ç§’ä»¥é¿å…é¢‘ç‡é™åˆ¶...")
    await asyncio.sleep(60)
    
    # æµ‹è¯•æŒ‡å®šUPä¸»
    logger.info("\n" + "="*60)
    logger.info("ç¬¬äºŒæ­¥: æµ‹è¯•æŒ‡å®šUPä¸»ä¿¡æ¯è·å–")
    
    uid = "1039025435"
    up_name = "æˆ˜å›½æ—¶ä»£_å§œæ±æ±½æ°´"
    
    success = await test_alternative_approach(uid, up_name)
    
    logger.info("\n" + "="*60)
    logger.info("ğŸ“Š æµ‹è¯•æ€»ç»“:")
    logger.info(f"   æŒ‡å®šUPä¸»æµ‹è¯•: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")
    
    if not success:
        logger.info("\nğŸ’¡ å»ºè®®:")
        logger.info("   1. ç­‰å¾…æ›´é•¿æ—¶é—´å†é‡è¯•ï¼ˆBç«™æœ‰ä¸¥æ ¼çš„é¢‘ç‡é™åˆ¶ï¼‰")
        logger.info("   2. è€ƒè™‘ä½¿ç”¨ä¸åŒçš„ç½‘ç»œç¯å¢ƒ")
        logger.info("   3. æ£€æŸ¥Cookieæ˜¯å¦ä»ç„¶æœ‰æ•ˆ")
        
        if sample_uid:
            logger.info(f"   4. å¯ä»¥å…ˆæµ‹è¯•ä»çƒ­é—¨è§†é¢‘ä¸­æ‰¾åˆ°çš„UPä¸»: {sample_uid}")

if __name__ == "__main__":
    asyncio.run(main()) 